# Pre-RMSNorm and Pre-CRMSNorm Transformers: Equivalent and Efficient Pre-LN Transformers

Play with `example.py` to see how we simplify the widely-used Pre-LN Transformers.

In the directories `jax` and `torch,` we provide scripts to compare the inference and training (on a single accelerator or multiple accelerators with distributed data-parallel (DDP) processing).
